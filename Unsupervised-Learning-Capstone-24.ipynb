{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "start=timeit.default_timer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project you'll dig into a large amount of text and apply most of what you've covered in this unit and in the course so far.\n",
    "\n",
    "First, pick a set of texts. This can be either a series of novels, chapters, or articles. Anything you'd like. It just has to have multiple entries of varying characteristics. At least 100 should be good. There should also be at least 10 different authors, but try to keep the texts related (either all on the same topic of from the same branch of literature - something to make classification a bit more difficult than obviously different subjects).\n",
    "\n",
    "This capstone can be an extension of your NLP challenge if you wish to use the same corpus. If you found problems with that data set that limited your analysis, however, it may be worth using what you learned to choose a new corpus. Reserve 25% of your corpus as a test set.\n",
    "\n",
    "The first technique is to create a series of clusters. Try several techniques and pick the one you think best represents your data. Make sure there is a narrative and reasoning around why you have chosen the given clusters. Are authors consistently grouped into the same cluster?\n",
    "\n",
    "Next, perform some unsupervised feature generation and selection using the techniques covered in this unit and elsewhere in the course. Using those features then build models to attempt to classify your texts by author. Try different permutations of unsupervised and supervised techniques to see which combinations have the best performance.\n",
    "\n",
    "Lastly return to your holdout group. Does your clustering on those members perform as you'd expect? Have your clusters remained stable or changed dramatically? What about your model? Is it's performance consistent?\n",
    "\n",
    "If there is a divergence in the relative stability of your model and your clusters, delve into why.\n",
    "\n",
    "Your end result should be a write up of how clustering and modeling compare for classifying your texts. What are the advantages of each? Why would you want to use one over the other? Approximately 3-5 pages is a good length for your write up, and remember to include visuals to help tell your story!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filename=['brady.txt','butler.txt','cutting.txt','dawson.txt','dyke.txt',\n",
    "          'hughes.txt','mitchell.txt','richmond.txt','rinehart.txt','stretton.txt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text(filename):\n",
    "    file=open(filename,'r')\n",
    "    text=file.read()\n",
    "    file.close\n",
    "    text=nlp(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=pd.DataFrame()\n",
    "for i in range(0,len(filename)):\n",
    "    text=load_text(filename[i])\n",
    "    author=filename[i].replace('.txt','')\n",
    "    text_sents=[[sent,author] for sent in text.sents]\n",
    "    text_df=pd.DataFrame(text_sents)\n",
    "    sentences=sentences.append(text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(ï»¿The, Project, Gutenberg, eBook, ,, And, Th...</td>\n",
       "      <td>brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Illustrated, by, Walter, B., Everett, \\n\\n\\n)</td>\n",
       "      <td>brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(This, eBook, is, for, the, use, of, anyone, a...</td>\n",
       "      <td>brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(You, may, copy, it, ,, give, it, away, or, \\n...</td>\n",
       "      <td>brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Title, :)</td>\n",
       "      <td>brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(And, Thus, He, Came, \\n\\n)</td>\n",
       "      <td>brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(Author, :, Cyrus, Townsend, Brady, \\n\\n, Rele...</td>\n",
       "      <td>brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(:, January, 5, ,, 2005,  )</td>\n",
       "      <td>brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>([, eBook, #, 14606, ], \\n\\n)</td>\n",
       "      <td>brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Language, :)</td>\n",
       "      <td>brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(English, \\n\\n, Character, set, encoding, :, I...</td>\n",
       "      <td>brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(*)</td>\n",
       "      <td>brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(*, *, START, OF, THE, PROJECT, GUTENBERG, EBO...</td>\n",
       "      <td>brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(THUS, HE, CAME, *)</td>\n",
       "      <td>brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(*, *, \\n\\n\\n, E, -, text, prepared, by, Rober...</td>\n",
       "      <td>brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(Note, :, Project, Gutenberg, also, has, an, H...</td>\n",
       "      <td>brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(See, 14606-h.htm, or, 14606-h.zip)</td>\n",
       "      <td>brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(:, \\n      , (, http://www.gutenberg.net/dirs...</td>\n",
       "      <td>brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(A, Christmas, Fantasy, \\n\\n, by, \\n\\n, CYRUS,...</td>\n",
       "      <td>brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(Pictures, by, Walter, B., Everett, \\n\\n, G.P....</td>\n",
       "      <td>brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>([, Illustration, :, \", No, ,, No, ,, \", said,...</td>\n",
       "      <td>brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(To, the, Beloved, Memory, \\n, of, \\n, Little,...</td>\n",
       "      <td>brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(I, .--)</td>\n",
       "      <td>brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(THE, BABY, \\n      , II, .--)</td>\n",
       "      <td>brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(THE, CHILD, \\n     , III, .--)</td>\n",
       "      <td>brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(THE, FRIEND, \\n      , IV, .--)</td>\n",
       "      <td>brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(THE, WORKMAN, \\n       , V, .--)</td>\n",
       "      <td>brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(THE, COMFORTER, \\n      , VI, .--)</td>\n",
       "      <td>brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(THE, BURDEN, BEARER, \\n     , VII, .--)</td>\n",
       "      <td>brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(THE, THORN, CROWNED, \\n    , VIII, .--)</td>\n",
       "      <td>brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>(The, Project, Gutenberg, Literary, Archive, F...</td>\n",
       "      <td>stretton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>(The, Foundation, 's, EIN, or, federal, tax, i...</td>\n",
       "      <td>stretton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>(Its, 501(c)(3, ), letter, is, posted, at, \\n,...</td>\n",
       "      <td>stretton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>(Contributions, to, the, Project, Gutenberg, \\n)</td>\n",
       "      <td>stretton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>(Literary, Archive, Foundation, are, tax, dedu...</td>\n",
       "      <td>stretton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>(The, Foundation, 's, principal, office, is, l...</td>\n",
       "      <td>stretton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>(Its, business, office, is, located, at, \\n, 8...</td>\n",
       "      <td>stretton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>(business@pglaf.org, .,  )</td>\n",
       "      <td>stretton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>(Email, contact, links, and, up, to, date, con...</td>\n",
       "      <td>stretton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>(Information, about, Donations, to, the, Proje...</td>\n",
       "      <td>stretton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>(Literary, Archive, Foundation, \\n\\n, Project,...</td>\n",
       "      <td>stretton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>(Many, small, donations, \\n, (, $, 1, to, $, 5...</td>\n",
       "      <td>stretton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>(The, Foundation, is, committed, to, complying...</td>\n",
       "      <td>stretton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>(Compliance, requirements, are, not, uniform, ...</td>\n",
       "      <td>stretton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>(We, do, not, solicit, donations, in, location...</td>\n",
       "      <td>stretton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>(To, \\n, SEND, DONATIONS, or, determine, the, ...</td>\n",
       "      <td>stretton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>(http://pglaf.org, \\n\\n, While, we, can, not, ...</td>\n",
       "      <td>stretton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>(,, we, know, of, no, prohibition, \\n, against...</td>\n",
       "      <td>stretton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>(International, donations, are, gratefully, ac...</td>\n",
       "      <td>stretton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>(U.S., laws, alone, swamp, our, small, staff, ...</td>\n",
       "      <td>stretton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>(Please, check, the, Project, Gutenberg, Web, ...</td>\n",
       "      <td>stretton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>(Donations, are, accepted, in, a, number, of, ...</td>\n",
       "      <td>stretton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>(To, donate, ,, please, visit, :, http://pglaf...</td>\n",
       "      <td>stretton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>(General, Information, About, Project, Gutenbe...</td>\n",
       "      <td>stretton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>(Professor, Michael, S., Hart, is, the, origin...</td>\n",
       "      <td>stretton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>(For, thirty, years, ,, he, produced, and, dis...</td>\n",
       "      <td>stretton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>(Project, Gutenberg, -, tm, eBooks, are, often...</td>\n",
       "      <td>stretton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>(Thus, ,, we, do, not, necessarily, \\n, keep, ...</td>\n",
       "      <td>stretton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>(Most, people, start, at, our, Web, site, whic...</td>\n",
       "      <td>stretton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>(This, Web, site, includes, information, about...</td>\n",
       "      <td>stretton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7224 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0         1\n",
       "0    (ï»¿The, Project, Gutenberg, eBook, ,, And, Th...     brady\n",
       "1       (Illustrated, by, Walter, B., Everett, \\n\\n\\n)     brady\n",
       "2    (This, eBook, is, for, the, use, of, anyone, a...     brady\n",
       "3    (You, may, copy, it, ,, give, it, away, or, \\n...     brady\n",
       "4                                           (Title, :)     brady\n",
       "5                          (And, Thus, He, Came, \\n\\n)     brady\n",
       "6    (Author, :, Cyrus, Townsend, Brady, \\n\\n, Rele...     brady\n",
       "7                          (:, January, 5, ,, 2005,  )     brady\n",
       "8                        ([, eBook, #, 14606, ], \\n\\n)     brady\n",
       "9                                        (Language, :)     brady\n",
       "10   (English, \\n\\n, Character, set, encoding, :, I...     brady\n",
       "11                                                 (*)     brady\n",
       "12   (*, *, START, OF, THE, PROJECT, GUTENBERG, EBO...     brady\n",
       "13                                 (THUS, HE, CAME, *)     brady\n",
       "14   (*, *, \\n\\n\\n, E, -, text, prepared, by, Rober...     brady\n",
       "15   (Note, :, Project, Gutenberg, also, has, an, H...     brady\n",
       "16                 (See, 14606-h.htm, or, 14606-h.zip)     brady\n",
       "17   (:, \\n      , (, http://www.gutenberg.net/dirs...     brady\n",
       "18   (A, Christmas, Fantasy, \\n\\n, by, \\n\\n, CYRUS,...     brady\n",
       "19   (Pictures, by, Walter, B., Everett, \\n\\n, G.P....     brady\n",
       "20   ([, Illustration, :, \", No, ,, No, ,, \", said,...     brady\n",
       "21   (To, the, Beloved, Memory, \\n, of, \\n, Little,...     brady\n",
       "22                                            (I, .--)     brady\n",
       "23                      (THE, BABY, \\n      , II, .--)     brady\n",
       "24                     (THE, CHILD, \\n     , III, .--)     brady\n",
       "25                    (THE, FRIEND, \\n      , IV, .--)     brady\n",
       "26                   (THE, WORKMAN, \\n       , V, .--)     brady\n",
       "27                 (THE, COMFORTER, \\n      , VI, .--)     brady\n",
       "28            (THE, BURDEN, BEARER, \\n     , VII, .--)     brady\n",
       "29            (THE, THORN, CROWNED, \\n    , VIII, .--)     brady\n",
       "..                                                 ...       ...\n",
       "642  (The, Project, Gutenberg, Literary, Archive, F...  stretton\n",
       "643  (The, Foundation, 's, EIN, or, federal, tax, i...  stretton\n",
       "644  (Its, 501(c)(3, ), letter, is, posted, at, \\n,...  stretton\n",
       "645   (Contributions, to, the, Project, Gutenberg, \\n)  stretton\n",
       "646  (Literary, Archive, Foundation, are, tax, dedu...  stretton\n",
       "647  (The, Foundation, 's, principal, office, is, l...  stretton\n",
       "648  (Its, business, office, is, located, at, \\n, 8...  stretton\n",
       "649                         (business@pglaf.org, .,  )  stretton\n",
       "650  (Email, contact, links, and, up, to, date, con...  stretton\n",
       "651  (Information, about, Donations, to, the, Proje...  stretton\n",
       "652  (Literary, Archive, Foundation, \\n\\n, Project,...  stretton\n",
       "653  (Many, small, donations, \\n, (, $, 1, to, $, 5...  stretton\n",
       "654  (The, Foundation, is, committed, to, complying...  stretton\n",
       "655  (Compliance, requirements, are, not, uniform, ...  stretton\n",
       "656  (We, do, not, solicit, donations, in, location...  stretton\n",
       "657  (To, \\n, SEND, DONATIONS, or, determine, the, ...  stretton\n",
       "658  (http://pglaf.org, \\n\\n, While, we, can, not, ...  stretton\n",
       "659  (,, we, know, of, no, prohibition, \\n, against...  stretton\n",
       "660  (International, donations, are, gratefully, ac...  stretton\n",
       "661  (U.S., laws, alone, swamp, our, small, staff, ...  stretton\n",
       "662  (Please, check, the, Project, Gutenberg, Web, ...  stretton\n",
       "663  (Donations, are, accepted, in, a, number, of, ...  stretton\n",
       "664  (To, donate, ,, please, visit, :, http://pglaf...  stretton\n",
       "665  (General, Information, About, Project, Gutenbe...  stretton\n",
       "666  (Professor, Michael, S., Hart, is, the, origin...  stretton\n",
       "667  (For, thirty, years, ,, he, produced, and, dis...  stretton\n",
       "668  (Project, Gutenberg, -, tm, eBooks, are, often...  stretton\n",
       "669  (Thus, ,, we, do, not, necessarily, \\n, keep, ...  stretton\n",
       "670  (Most, people, start, at, our, Web, site, whic...  stretton\n",
       "671  (This, Web, site, includes, information, about...  stretton\n",
       "\n",
       "[7224 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "**START OF THE PROJECT GUTENBERG EBOOK AND"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.iloc[,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-6fcf9dfbd479>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 50 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "      \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words=set()\n",
    "for i in range(0,len(filename)):\n",
    "    text=load_text(filename[i])\n",
    "    words=bag_of_words(text)\n",
    "    common_words.update(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words=[i.strip() for i in common_words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words=[c for c in common_words if c.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS=list(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words=[x for x in common_words if x not in STOP_WORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop=['copyright','good','great','gutenberg','project',',oh','th',\n",
    "     'christmas','tree','mary','claus']\n",
    "common_words=[x for x in common_words if x not in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(index=range(len(sentences)),columns=common_words)\n",
    "    df['text_sentence'] = sentences[0].values\n",
    "    df['text_source'] = sentences[1].values\n",
    "    df.loc[:,common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 500 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "       \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "word_counts = bow_features(sentences, common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source'], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfc = ensemble.RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop=timeit.default_timer()\n",
    "time_used=stop-start\n",
    "print(\"Time Used:\",time_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
